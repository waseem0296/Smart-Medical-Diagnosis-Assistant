# ğŸ§  Smart Medical Diagnosis Assistant

The **Smart Medical Diagnosis Assistant** is an AI-powered system that allows patients to interact with a **virtual doctor** through **text** and **voice**. It combines advanced **Large Language Models (LLMs)**, **speech recognition**, **emotion detection**, and **text-to-speech** to deliver **empathetic and medically relevant responses**.

This project is modular, consisting of different components for AI reasoning, frontend UI, voice processing, and emotion detection. It is built with **Flask (backend)**, **Streamlit (frontend)**, and **Groq + Gemini APIs** for AI capabilities.

---

## âœ¨ Features

- ğŸ’¬ **Chatbot (Text)** â†’ Ask questions and get AI-powered responses.
- ğŸ¤ **Voice Input** â†’ Speak your question, which is transcribed automatically.
- ğŸ­ **Emotion Detection** â†’ The assistant detects your emotional tone (e.g., calm, anxious, distressed).
- ğŸ—£ **Voice Output** â†’ The doctor responds with natural-sounding speech.
- ğŸ§© **Modular Design** â†’ Each function (AI, voice, emotion) is separated for easy development.
- ğŸ”’ **Secure API Management** via `.env`.

---

## ğŸ“‚ Project Structure

Smart-Medical-Diagnosis-Assistant/

â”‚â”€â”€ ai_brain.py # AI reasoning logic with Groq LLaMA model

â”‚â”€â”€ frontend.py # Streamlit-based chatbot UI

â”‚â”€â”€ voice_of_doctor.py # Doctor's voice synthesis (Text-to-Speech)

â”‚â”€â”€ voice_of_patient.py # Patient's voice recording + transcription

â”‚â”€â”€ emotion_model.py # Detects emotion from patient audio

â”‚â”€â”€ app.py # Flask backend connecting all modules

â”‚â”€â”€ .env # Environment variables (ignored by Git)

â”‚â”€â”€ requirements.txt # Dependencies


---

## âš™ï¸ Components Overview

### 1. **AI Brain (`ai_brain.py`)**
- Uses Groqâ€™s **LLaMA 3.1 8B-Instant** for reasoning.
- Provides `ask_text_model(user_input)` function.
- Future-ready for **image analysis** (commented prototype inside code).

### 2. **Voice of Patient (`voice_of_patient.py`)**
- Records voice input using `speech_recognition`.
- Converts audio to `.mp3` using `pydub`.
- Transcribes audio â†’ text using Groqâ€™s **Whisper-Large-v3** ASR.

### 3. **Emotion Model (`emotion_model.py`)**
- Uses **Google Gemini 1.5 Flash** to classify audio emotions.
- Supports labels: `calm, anxious, distressed, angry, happy, neutral`.
- Returns most likely emotion as plain text.

### 4. **Voice of Doctor (`voice_of_doctor.py`)**
- Converts doctorâ€™s AI-generated answers into voice using **gTTS**.
- Saves response as `.mp3`.
- Plays audio automatically (uses `ffplay` on Windows).

### 5. **Backend (`app.py`)**
- Built with Flask.
- Endpoints:
  - `/ask` â†’ Handles text queries.
  - `/voice` â†’ Handles full voice pipeline:
    - Record patientâ€™s voice
    - Transcribe â†’ text
    - Detect emotion
    - Build enriched query: *text + emotion*
    - Generate empathetic answer with Groq LLM
    - Convert to speech & return JSON: `{transcription, emotion, answer}`

### 6. **Frontend (`frontend.py`)**
- Built with Streamlit.
- Provides a **chat-style UI** for patients.
- Two input modes:
  - Text input box
  - ğŸ¤ Voice button (records and sends to `/voice`)
- Maintains conversation history (`st.session_state`).

---

## ğŸ›  Installation

### 1. Clone Repository
```bash
git clone https://github.com/<your-username>/Smart-Medical-Diagnosis-Assistant.git
cd Smart-Medical-Diagnosis-Assistant
```

## Create Virtual Environment
python -m venv venv
venv\Scripts\activate   # On Windows
source venv/bin/activate # On Linux/Mac

## Install Dependencies
pip install -r requirements.txt

## Configure Environment Variables

Create a .env file in the root folder:

GROQ_API_KEY=your_groq_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here




## â–¶ï¸ Running the Project

Start Flask backend:

python app.py


Start Streamlit frontend:

streamlit run frontend.py


Open browser â†’ http://localhost:8501

You can now:

Type questions into the chat.

Use ğŸ¤ button to ask by voice.

Receive doctorâ€™s answers in text + voice.

ğŸ“¦ Requirements

Example requirements.txt:

flask
flask-cors
streamlit
requests
python-dotenv
groq
gtts
pydub
SpeechRecognition
google-generativeai


## System Dependencies:

FFmpeg (for audio playback in voice_of_doctor.py)

PortAudio (needed for speech_recognition)

## ğŸ“Œ Future Enhancements

ğŸ–¼ Medical image analysis (X-rays, MRIs).

ğŸŒ Multi-language support.

â˜ï¸ Deployment to cloud (Heroku / AWS / Streamlit Cloud).

ğŸ“– Patient medical history tracking.

ğŸ‘¨â€âš•ï¸ Integration with real doctors for telemedicine.

ğŸ”’ Security Notes

.env is added to .gitignore.

Never commit real API keys.

Use a dummy .env.example file for collaboration:

GROQ_API_KEY=your_key_here
GEMINI_API_KEY=your_key_here

ğŸ§‘â€ğŸ¤â€ğŸ§‘ Authors & Contributors

Waseem Abbas (Project Lead & Developer)

Open for collaboration: Contributions, issues, and feature requests are welcome!

